Dataset Description 

This dataset contains only MNI‐normalized BOLDs from fMRIPrep.

Participants: 54 meditation-trained participants (29 LKM, 25 PMR) scanned ≤ 2 weeks post-training

Scanning Site & Hardware: Center for Functional and Molecular Imaging (Georgetown University) using a 3 T Siemens TIM Trio with a 64-channel phased-array head coil. 

Acquisition Parameters: Structural (T1 MP-RAGE): 176 slices, 1 mm isotropic voxels; TR = 1,900 ms; TE = 2.52 ms; matrix = 256 × 256; FoV = 250 mm; Functional (T2 EPI):* 46 transversal slices, 3 mm isotropic voxels; TR = 2,500 ms; TE = 30 ms; matrix = 64 × 64; FoV = 192 mm. 
PMC

Task Structure: Two counter-balanced runs—Experience (Self) and Observe (Other) —each with 30 trials (15 fear-anticipation, 15 pain-experience); Audio cues (distinct beeps/buzzes) and text cues (white screen, descriptive black text) signal whether the participant or a study partner may/will not receive pressure-pain; Before scanning, each participant briefly meets a stranger “study partner,” told to be seated next door and who's hand is visible via live video during the scan to enhance empathic engagement; Computer-controlled pneumatic device applies pressure (2.5–125 PSI, capped at 80 PSI for safety) to the lunula of the right thumbnail via a 1 cm² plastic probe; Device sits outside the magnet; pressure delivered through a flexible tube to a piston fixed on the participant’s (or partner’s) thumbnail; Pre-scan calibration ensures each participant experiences a matched “moderately painful” intensity.

- 30 trials
    - 30 cues (15 neutral, 15 pain)
    - 30 anticipation (15 neutral, 15 pain)
    - 30 stimulation (10 pain, 20 no pain)
    - 30 rest (10 pain, 20 no pain)

- 1 trial = 24 seconds 
    - 3 s auditory signal for anticipation or safety (pain may or may not occur)
    - 3-12 s anticipation
    - 6 s pain stimulation (including 1 s pain/no pain cue)
    - 3-12 rest (anticipation and rest always add up to 15 s)

- Task time
     - acquisition time is 750 s 
    -  pure task time is 720 s per run (about 12 min, so total task time is 24 min)
    - subtracted 10 s (4 volumes) from imaging data, events, and confounds

NOTE: The confound (and outlier) files are trimmed (3 volumes in the beginning and 3 at the end, as can be seen in the getConfounds.py file, line 53, on GitHub in the folder fMRI_Data_Python_Bash_Scripts). So they contain 290 volumes (725 s) instead of 296 (740 s). However, the fMRI data on OpenNeuro is not trimmed. They are being trimmed during the first-level analysis, for which you can also find the script on GitHub. It's the 1stlevel_smoothed.sh file, lines 51, 64, 68 in the folder fMRI_Data_Python_Bash_Scripts. 

Preprint on ResearchSquare: Loneliness predicts reduced self-reported empathy but not empathic multi-voxel neural response patterns after meditation training (Currently the manuscript is under review at Communications Psychology)

OSF: https://osf.io/2sx3v/
Scripts to run the analysis: https://github.com/princessamygdala/loneliness-empathy-meditation-study
